# app.py
# -*- coding: utf-8 -*-

import os
import sys
import pickle
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st

# SHAP ä¾èµ–è¾ƒé‡ï¼Œæ”¾åœ¨åé¢æŒ‰éœ€ import ä¹Ÿå¯ä»¥
import shap
import matplotlib.pyplot as plt


# ======================
# 1) é¡µé¢è®¾ç½®
# ======================
st.set_page_config(
    page_title="Respiratory Failure Risk Calculator (SVM)",
    page_icon="ğŸ«",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown(
    """
# ğŸ« Respiratory Failure Risk Calculator (SVM)
è¾“å…¥ä¸´åºŠå˜é‡ â†’ è¾“å‡ºä¸ªä½“é£é™©ï¼ˆæ¦‚ç‡ï¼‰+ å•ä¾‹ SHAP è§£é‡Šï¼ˆwaterfallï¼‰
"""
)
st.info("æç¤ºï¼šè¯¥å·¥å…·ç”¨äºç§‘ç ”å±•ç¤ºä¸è¾…åŠ©å†³ç­–ï¼Œä¸æ›¿ä»£ä¸´åºŠåŒ»ç”Ÿåˆ¤æ–­ã€‚")


# ======================
# 2) è·¯å¾„ä¸å¸¸é‡
# ======================
BASE_DIR = Path(__file__).resolve().parent  # Streamlit/Cloud ç¯å¢ƒå¯ç”¨
MODEL_PATH = BASE_DIR / "svm_model.pkl"
SCALER_PATH = BASE_DIR / "scaler.pkl"
BG_PATH = BASE_DIR / "shap_background.pkl"

FEATURE_COLS = ["Age", "PaO2", "PF_ratio", "pneumonia", "ISS"]


# ======================
# 3) åŠ è½½æ¨¡å‹/Scaler/SHAP background
# ======================
@st.cache_resource(show_spinner=True)
def load_assets():
    # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
    missing = []
    for p in [MODEL_PATH, SCALER_PATH, BG_PATH]:
        if not p.exists():
            missing.append(str(p))
    if missing:
        raise FileNotFoundError("Missing required file(s):\n" + "\n".join(missing))

    # è¯»å– pkl
    with open(MODEL_PATH, "rb") as f:
        model = pickle.load(f)

    with open(SCALER_PATH, "rb") as f:
        scaler = pickle.load(f)

    with open(BG_PATH, "rb") as f:
        bg = pickle.load(f)

    # background æœŸæœ›æ˜¯ (n, 5)
    bg = np.array(bg)
    if bg.ndim != 2 or bg.shape[1] != len(FEATURE_COLS):
        raise ValueError(f"shap_background shape should be (n,{len(FEATURE_COLS)}), got {bg.shape}")

    return model, scaler, bg


def safe_predict_proba(model, X_scaled_df: pd.DataFrame) -> float:
    """è¿”å›æ­£ç±»æ¦‚ç‡"""
    if not hasattr(model, "predict_proba"):
        raise AttributeError("Model does not support predict_proba(). è¯·ç¡®è®¤è®­ç»ƒæ—¶å¼€å¯ probability=True çš„ SVCã€‚")
    proba = model.predict_proba(X_scaled_df)
    return float(proba[0, 1])


def build_kernel_explainer(model, bg_scaled_df: pd.DataFrame):
    """KernelExplainerï¼šç”¨ predict_proba è¾“å‡ºæ¦‚ç‡ï¼Œlink='logit' æ›´é€‚åˆåˆ†ç±»æ¦‚ç‡"""
    # shap éœ€è¦å‡½æ•°ï¼šè¾“å…¥ numpy -> è¾“å‡ºæ¦‚ç‡çŸ©é˜µ
    def f(X_np):
        X_df = pd.DataFrame(X_np, columns=FEATURE_COLS)
        return model.predict_proba(X_df)

    explainer = shap.KernelExplainer(f, bg_scaled_df.values, link="logit")
    return explainer


def plot_shap_waterfall(explainer, x_scaled_df: pd.DataFrame, feature_names):
    """
    ç”Ÿæˆ waterfall å›¾ï¼ˆmatplotlibï¼‰ï¼Œè¿”å› fig
    """
    # shap_values: (1, n_features) for class=1
    shap_values = explainer.shap_values(x_scaled_df.values, nsamples=200)
    # äºŒåˆ†ç±» KernelExplainer å¯èƒ½è¿”å› list: [class0, class1]
    if isinstance(shap_values, list):
        sv = shap_values[1][0]
        base_value = explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value
    else:
        sv = shap_values[0]
        base_value = explainer.expected_value

    x_raw = x_scaled_df.iloc[0].values

    # æ„é€  Explanation
    exp = shap.Explanation(
        values=sv,
        base_values=base_value,
        data=x_raw,
        feature_names=list(feature_names),
    )

    fig = plt.figure(figsize=(7.2, 4.2), dpi=160)
    shap.plots.waterfall(exp, max_display=len(feature_names), show=False)
    plt.tight_layout()
    return fig, sv


# ======================
# 4) ä¾§è¾¹æ è¾“å…¥
# ======================
with st.sidebar:
    st.header("Input features")

    age = st.number_input("Age (years)", min_value=0.0, max_value=120.0, value=60.0, step=1.0)
    pao2 = st.number_input("PaOâ‚‚ (mmHg)", min_value=0.0, max_value=500.0, value=80.0, step=1.0)
    pf = st.number_input("PF ratio (PaOâ‚‚/FiOâ‚‚)", min_value=0.0, max_value=800.0, value=250.0, step=5.0)

    pneumonia = st.selectbox("Pulmonary infection / Pneumonia (0/1)", [0, 1], index=1)
    iss = st.number_input("ISS (Injury Severity Score)", min_value=0.0, max_value=75.0, value=25.0, step=1.0)

    st.divider()

    pt_custom = st.slider("Decision threshold (pt)", min_value=0.05, max_value=0.95, value=0.40, step=0.01)
    st.caption("å»ºè®®ç”¨äºè®ºæ–‡é˜ˆå€¼è§£é‡Šï¼špt=0.20 / 0.40 / 0.60ï¼ˆä¸‰æ¡£ï¼‰")


# ======================
# 5) ä¸»é€»è¾‘ï¼šåŠ è½½ + é¢„æµ‹ + SHAP
# ======================
try:
    model, scaler, bg = load_assets()
except Exception as e:
    st.error("æ¨¡å‹èµ„æºåŠ è½½å¤±è´¥ï¼ˆè¯·æ£€æŸ¥ app.py åŒç›®å½•ä¸‹çš„ pkl æ–‡ä»¶æ˜¯å¦é½å…¨ä¸”å¯è¯»å–ï¼‰")
    st.exception(e)
    st.stop()

# raw è¾“å…¥
X_raw = pd.DataFrame(
    [[age, pao2, pf, pneumonia, iss]],
    columns=FEATURE_COLS
)

# æ ‡å‡†åŒ–
try:
    X_scaled_np = scaler.transform(X_raw.values)
    X_scaled = pd.DataFrame(X_scaled_np, columns=FEATURE_COLS)
except Exception as e:
    st.error("æ ‡å‡†åŒ– scaler.transform å¤±è´¥ï¼šè¯·ç¡®è®¤ scaler ä¸ç‰¹å¾åˆ—é¡ºåºä¸€è‡´ã€‚")
    st.exception(e)
    st.stop()

# é¢„æµ‹æ¦‚ç‡
try:
    prob = safe_predict_proba(model, X_scaled)
except Exception as e:
    st.error("predict_proba å¤±è´¥ï¼šè¯·ç¡®è®¤ä½ çš„ SVM è®­ç»ƒæ—¶è®¾ç½®äº† probability=Trueï¼Œå¹¶ä¸”æ¨¡å‹å¯æ­£å¸¸åŠ è½½ã€‚")
    st.exception(e)
    st.stop()

risk_label = "High risk" if prob >= pt_custom else "Low risk"
cost_benefit = pt_custom / (1 - pt_custom)


# ======================
# 6) é¡µé¢å¸ƒå±€ï¼šä¸¤åˆ—
# ======================
col1, col2 = st.columns([1.05, 1.0], gap="large")

with col1:
    st.subheader("Prediction")

    st.metric("Predicted risk (probability)", f"{prob:.3f}")

    if prob >= pt_custom:
        st.error(f"Decision (pt={pt_custom:.2f}): {risk_label}")
    else:
        st.success(f"Decision (pt={pt_custom:.2f}): {risk_label}")

    st.caption(f"Cost:Benefit ratio = pt/(1-pt) = {cost_benefit:.3f}")

    st.write("Raw input:")
    st.dataframe(X_raw, use_container_width=True)

    # ä¸‹è½½ç»“æœ
    out = X_raw.copy()
    out["pred_prob"] = prob
    out["decision_pt"] = pt_custom
    out["risk_label"] = risk_label
    st.download_button(
        "Download this case (CSV)",
        out.to_csv(index=False).encode("utf-8-sig"),
        file_name="svm_single_case_result.csv",
        mime="text/csv",
    )

with col2:
    st.subheader("Single-case SHAP (waterfall)")

    # background ä¹Ÿè¦ç”¨ scaler æ ‡å‡†åŒ–åçš„ç‰ˆæœ¬
    try:
        bg_scaled = pd.DataFrame(scaler.transform(bg), columns=FEATURE_COLS)
        explainer = build_kernel_explainer(model, bg_scaled)

        with st.spinner("Computing SHAP (KernelExplainer)â€¦"):
            fig, sv = plot_shap_waterfall(explainer, X_scaled, FEATURE_COLS)

        st.pyplot(fig, clear_figure=True)

        # Top è´¡çŒ®è¡¨
        contrib = (
            pd.DataFrame({"Feature": FEATURE_COLS, "SHAP": sv})
            .assign(absSHAP=lambda d: d["SHAP"].abs())
            .sort_values("absSHAP", ascending=False)
            .drop(columns="absSHAP")
        )
        st.write("Top contributors (absolute SHAP):")
        st.dataframe(contrib, use_container_width=True)

    except Exception as e:
        st.warning("SHAP è§£é‡Šç”Ÿæˆå¤±è´¥ï¼ˆä¸å½±å“æ¦‚ç‡è¾“å‡ºï¼‰ã€‚å¸¸è§åŸå› ï¼šshap/numba åœ¨äº‘ç«¯æ„å»ºä¸å…¼å®¹æˆ–è®¡ç®—è¶…æ—¶ã€‚")
        st.exception(e)


# ======================
# 7) ä¸‹æ–¹ï¼šä¸‰æ¡£é˜ˆå€¼è§£é‡Šï¼ˆè®ºæ–‡å‹å¥½ï¼‰
# ======================
st.divider()
st.subheader("Clinical threshold interpretation (recommended for reporting)")

thr_list = [0.20, 0.40, 0.60]
thr_table = pd.DataFrame({
    "Threshold (pt)": thr_list,
    "Clinical strategy": ["Low threshold (high sensitivity / screening)",
                          "Middle threshold (balanced)",
                          "High threshold (high specificity / confirmatory)"],
    "Cost:Benefit (pt/(1-pt))": [t/(1-t) for t in thr_list],
})
thr_table["Cost:Benefit (pt/(1-pt))"] = thr_table["Cost:Benefit (pt/(1-pt))"].map(lambda x: f"{x:.3f}")
st.dataframe(thr_table, use_container_width=True)

st.caption("å†™ä½œå»ºè®®ï¼šä¸è¦åªæŠ¥å‘Š Youdenã€‚å¯ä»¥ç”¨ DCA + CIC åœ¨ pt=0.20/0.40/0.60 ä¸‰ä¸ªç‚¹åˆ†åˆ«è§£è¯»ï¼Œå½¢æˆä½/ä¸­/é«˜é˜ˆå€¼çš„ä¸´åºŠç­–ç•¥æè¿°ã€‚")
